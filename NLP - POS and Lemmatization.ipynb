{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqeN8RE4YX-6",
        "colab_type": "text"
      },
      "source": [
        "###**NLP - Continue**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krCKqZFYYhDs",
        "colab_type": "text"
      },
      "source": [
        "**Parts of Speech**\n",
        "\n",
        "1. tags (tells us the parts of speech of each word) \n",
        "2. pos_tags (tells us the parts of speech of each word) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Zp3opPdYgPX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Importing Textblob from textblob\n",
        "from textblob import TextBlob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-q4Dmx5ZfKy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mystr2 = 'There is a need to follow two important things to fight this pandemic — resolve \tand restraint,” he said in a televised address on Thursday. He appealed to businesses to act with empathy, while assuring people that there are no shortages and telling them to avoid panic buying. Senior citizens should stay indoors and others should not leave home unless essential. The country needed to \tbe vigilant and it would be wrong to assume that the coronavirus won’t have a greater impact than it already has.'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXiXBaMfYpi8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "blob1 = TextBlob(mystr2) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQ8erKreZ8Rb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "49baa678-a1e8-4f09-8094-93c9910885e4"
      },
      "source": [
        "#Let's check the type of blob1\n",
        "type(blob1)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "textblob.blob.TextBlob"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8KloOotaB48",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "e0ccb15e-7aa7-48da-d10b-3cff6dc628a7"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')    \n",
        "nltk.download('averaged_perceptron_tagger')    #Usefuk for POS Tags\n",
        "nltk.download('brown')   #useful for noun_phrase"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFIaPAwtaGLv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2eb20972-7033-4224-8380-bf7ce93df37f"
      },
      "source": [
        "blob1.tags   #The output will tell the pos of each word of the textblob(mystr2) \n",
        "\n",
        "#blob1.pos_tags  #The output will tell the pos of each word of the textblob(mystr2) "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('There', 'EX'),\n",
              " ('is', 'VBZ'),\n",
              " ('a', 'DT'),\n",
              " ('need', 'NN'),\n",
              " ('to', 'TO'),\n",
              " ('follow', 'VB'),\n",
              " ('two', 'CD'),\n",
              " ('important', 'JJ'),\n",
              " ('things', 'NNS'),\n",
              " ('to', 'TO'),\n",
              " ('fight', 'VB'),\n",
              " ('this', 'DT'),\n",
              " ('pandemic', 'JJ'),\n",
              " ('—', 'NN'),\n",
              " ('resolve', 'NN'),\n",
              " ('and', 'CC'),\n",
              " ('restraint', 'NN'),\n",
              " ('”', 'NN'),\n",
              " ('he', 'PRP'),\n",
              " ('said', 'VBD'),\n",
              " ('in', 'IN'),\n",
              " ('a', 'DT'),\n",
              " ('televised', 'JJ'),\n",
              " ('address', 'NN'),\n",
              " ('on', 'IN'),\n",
              " ('Thursday', 'NNP'),\n",
              " ('He', 'PRP'),\n",
              " ('appealed', 'VBD'),\n",
              " ('to', 'TO'),\n",
              " ('businesses', 'NNS'),\n",
              " ('to', 'TO'),\n",
              " ('act', 'VB'),\n",
              " ('with', 'IN'),\n",
              " ('empathy', 'JJ'),\n",
              " ('while', 'IN'),\n",
              " ('assuring', 'VBG'),\n",
              " ('people', 'NNS'),\n",
              " ('that', 'IN'),\n",
              " ('there', 'EX'),\n",
              " ('are', 'VBP'),\n",
              " ('no', 'DT'),\n",
              " ('shortages', 'NNS'),\n",
              " ('and', 'CC'),\n",
              " ('telling', 'VBG'),\n",
              " ('them', 'PRP'),\n",
              " ('to', 'TO'),\n",
              " ('avoid', 'VB'),\n",
              " ('panic', 'JJ'),\n",
              " ('buying', 'NN'),\n",
              " ('Senior', 'JJ'),\n",
              " ('citizens', 'NNS'),\n",
              " ('should', 'MD'),\n",
              " ('stay', 'VB'),\n",
              " ('indoors', 'NNS'),\n",
              " ('and', 'CC'),\n",
              " ('others', 'NNS'),\n",
              " ('should', 'MD'),\n",
              " ('not', 'RB'),\n",
              " ('leave', 'VB'),\n",
              " ('home', 'NN'),\n",
              " ('unless', 'IN'),\n",
              " ('essential', 'JJ'),\n",
              " ('The', 'DT'),\n",
              " ('country', 'NN'),\n",
              " ('needed', 'VBD'),\n",
              " ('to', 'TO'),\n",
              " ('be', 'VB'),\n",
              " ('vigilant', 'JJ'),\n",
              " ('and', 'CC'),\n",
              " ('it', 'PRP'),\n",
              " ('would', 'MD'),\n",
              " ('be', 'VB'),\n",
              " ('wrong', 'JJ'),\n",
              " ('to', 'TO'),\n",
              " ('assume', 'VB'),\n",
              " ('that', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('coronavirus', 'NN'),\n",
              " ('won', 'VBD'),\n",
              " ('’', 'NNP'),\n",
              " ('t', 'NNS'),\n",
              " ('have', 'VBP'),\n",
              " ('a', 'DT'),\n",
              " ('greater', 'JJR'),\n",
              " ('impact', 'NN'),\n",
              " ('than', 'IN'),\n",
              " ('it', 'PRP'),\n",
              " ('already', 'RB'),\n",
              " ('has', 'VBZ')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZygK9S4ScTU6",
        "colab_type": "text"
      },
      "source": [
        "**Noun_Phrase**\n",
        "\n",
        "A list-like collection of words.\n",
        "\n",
        "Init docstring:\n",
        "\n",
        "Initialize a WordList. Takes a collection of strings as its only argument.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSWB0w2IdR1P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mystr3 = 'During this curfew, we shall neither leave our homes, nor get onto the streets \t\tor roam about our localities. Only those associated with emergency and essential \tservices will leave home,” the PM said. “This Janata Curfew will in a way be a \t\tlitmus test for us. This is also the time to see how prepared India is to fight \t\toff a global pandemic like the coronavirus.'\n",
        "blob2 = TextBlob(mystr3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0NvtwsnaVvf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "19e0e200-c08a-4053-d6ca-57cc0d3f5a76"
      },
      "source": [
        "for np in blob2.noun_phrases:   #Helps us know who or what\n",
        "  print(np)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "essential services\n",
            "pm\n",
            "janata curfew\n",
            "litmus test\n",
            "india\n",
            "global pandemic\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLyqeKxZeHHF",
        "colab_type": "text"
      },
      "source": [
        "**How do we find verbs**\n",
        "  1. TO know how or actions done\n",
        "  2. POS\n",
        "  3. Tokens\n",
        "\n",
        "**Quick Method**\n",
        "  1. blob.tags  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJlqnT1UbR49",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "e6cf6765-f0a6-4967-e20b-bf30aff92957"
      },
      "source": [
        "#['VB','VBZ','VBP','VBD','VBN','VBG']\n",
        "#for word,verb in blob2.tags:\n",
        " # print(f'{word} = > {verb}')\n",
        "\n",
        "for word,verb in blob2.tags:\n",
        "  if verb in ['VB','VBZ','VBP','VBD','VBN','VBG']:\n",
        "    print(f'{word} = > {verb}')\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "leave = > VB\n",
            "get = > VB\n",
            "roam = > VB\n",
            "associated = > VBN\n",
            "leave = > VB\n",
            "” = > VBP\n",
            "said = > VBD\n",
            "be = > VB\n",
            "is = > VBZ\n",
            "see = > VB\n",
            "is = > VBZ\n",
            "fight = > VB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcwcFg_IfpW6",
        "colab_type": "text"
      },
      "source": [
        "###**Lemmatization**\n",
        "\n",
        "1. Word Inflectioin = Word formation by adding to the base word / root word\n",
        "2. Singluarising or Pluralizing\n",
        "3. Stemming\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMW8RT4bfHAh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0e146445-d732-476c-8a41-da6c509005e5"
      },
      "source": [
        "blob2.pos_tagger   #NLTKTagger\n",
        "#Tagger that uses NLTK's standard TreeBank tagger.\n",
        "#NOTE: Requires numpy. Not yet supported with PyPy"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<textblob.en.taggers.NLTKTagger at 0x7f296db1ad30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pM1voUPrguXv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Let's create 2 lists\n",
        "\n",
        "list1 = ['buy','buying','buys','bought']\n",
        "list2 = ['bring','bringing','brought','brings']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z158vNDxhsj1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from textblob import TextBlob, Word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yf_kagyFh4Ui",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6a654a41-9306-484b-bec0-1b8f54411378"
      },
      "source": [
        "string = Word('books')    #singular form of books\n",
        "string.singularize()\n",
        "\n",
        "string2 = Word('dollar')  #Plural form of dollar\n",
        "string2.pluralize() "
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'dollars'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzDMeFxIkaYO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f72dd4ee-d392-4c4b-8549-6e0a9fa11619"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')   #Useful for lemmatization"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_nmhgwSiAVM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "7b397503-466c-44d6-c871-796f8968b467"
      },
      "source": [
        "for i in list1:\n",
        "  result = Word(i).lemmatize('v')\n",
        "  print(f'{i} = > {result}')\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "buy = > buy\n",
            "buying = > buy\n",
            "buys = > buy\n",
            "bought = > buy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxsaQPwKkS2h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "05e507ca-2875-408f-9304-22cec55b78b9"
      },
      "source": [
        "for i in list2:\n",
        "  result = Word(i).lemmatize('n')\n",
        "  print(f'{i} = > {result}')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bring = > bring\n",
            "bringing = > bringing\n",
            "brought = > brought\n",
            "brings = > brings\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWFO7Fick9yu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}