{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Tutorial - Working with PDF File.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPkABt8gNVSl0Iyd9RtBAr4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kirtiwardhan01/NLP---Natural-Language-Processing/blob/master/NLP_Tutorial_Working_with_PDF_File.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYTxPSVlIFDz",
        "outputId": "c4c67911-94cb-4fea-edee-d09e5d0b4c7c"
      },
      "source": [
        "#We need to insatll library that's useful in working with PDF File\n",
        "!pip install PyPDF2"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.7/dist-packages (1.26.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDWgNUZxJjX5"
      },
      "source": [
        "from google.colab import files\n",
        "import PyPDF2"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "OyQHIZRRKllF",
        "outputId": "04646e56-cc69-416b-ef43-76117ba2a2da"
      },
      "source": [
        "#Upload files \n",
        "upload = files.upload()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-00bd83a0-558b-41d0-9415-94b56df76783\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-00bd83a0-558b-41d0-9415-94b56df76783\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Kavitha Reddy Resume.pdf to Kavitha Reddy Resume (1).pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etbtLmyjKyc4",
        "outputId": "00b4b4f6-e1be-48b4-eee1-e6fb34928162"
      },
      "source": [
        "#To know if the file is uploaded or not then use !ls\n",
        "!ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Kavitha Reddy Resume.pdf'   sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIjYoS47LSP1"
      },
      "source": [
        "#Open the file      Mode = 'rb' (read binary mode)\n",
        "myfile = open('Kavitha Reddy Resume.pdf',mode='rb')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4MmPToxL-LQ"
      },
      "source": [
        "#To read the pdf file\n",
        "\n",
        "pdf_reader = PyPDF2.PdfFileReader(myfile)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odvyJNA8MTnW",
        "outputId": "64ef8658-5246-475d-ea6d-050e3e4e2fe3"
      },
      "source": [
        "pdf_reader.numPages          #Don't use () as it's not a function but an attribute   #Num of pages\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyIiZUf0M4Z6"
      },
      "source": [
        "#Get specific page\n",
        "page_one = pdf_reader.getPage(0)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "cgEZ6fToNUuC",
        "outputId": "ad627653-3e3b-41a4-9b57-5fe10a78f43c"
      },
      "source": [
        "page_one.extractText()     #Extracting the text from the page"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Kavitha Reddy\\n \\nEmail ID: \\nkavithareddybathini.522@gmail.com\\n, \\nPhone: 9000313641\\n \\n \\nSummary:\\n \\n\\n \\nProcess oriented Data Scientist with 2.8 years of experience and 4.8 years in\\n \\nSDLC.\\n \\n\\n \\nExperience in \\ntranslating business requirements to Data science\\n \\nsolutions\\n \\n\\n \\nProficient in Statistical Analysis, Machine learning and Deep learning\\n \\nAlgorithms\\n \\n\\n \\nExperienced in implementing CRISP\\n-\\nDM process for\\n \\nprojects\\n \\n\\n \\nHave good exposure to advance programming in Python and\\n \\nR\\n \\n\\n \\nGood knowledge in Hadoop and its components like HDFS, Map Reduce, Apache Pig, Hive, Sqoop, HBase \\nand\\n \\nOozie.\\n \\nExperience:\\n \\nDatafactZ /Diwo\\n \\n(Data\\n \\nScientist)\\n \\nApril 2017 \\n\\n \\nDec\\n \\n2019\\n \\n\\n \\nPerformed \\ndata analysis, statistical modeling, feature engineering, model tuni\\nng and selection \\non daily \\nbasis\\n \\n\\n \\nUsed the concept of \\nStacking, Bagging, Boosting, Feature Importance and Selection, PCA \\netc. in real\\n-\\n \\nworld projects to enhance model\\n \\nperformances\\n \\n\\n \\nExecuted Projects for clients like \\nL Brands , Flagstar and\\n \\nAspire\\n \\n\\n \\nImplemented \\ndemand forecasting for predicting sales of a\\n \\ncustomer\\n \\n\\n \\nInvolved with business stakeholders in developing HR analytics for customer\\n \\nretention\\n \\n\\n \\nExplored \\nML flow \\ntool for hosting models in \\nAzure\\n, and calling using REST\\n \\nAPI\\n \\n\\n \\nAttended Weekly calls with the onsite \\nteam mainly interacting with \\nPrincipal Business Architect\\n \\nand\\n \\nSenior Data Scientist \\nTeam\\n \\n\\n \\nInteracting with the business partners on regular basis for product\\n \\nenhancement\\n \\n\\n \\nCreated ASK scenarios for ASK module in the DIWO product which shows the insights for t\\nhe\\n \\nbusiness\\n \\n\\n \\nEngaging with clients to analyze opportunities for business growth and provide actionable\\n \\ninsights\\n \\n\\n \\nRecognized as best employee of the month award in\\n \\nDataFactZ/Diwo\\n \\nDatapoint Info Solutions Pvt Ltd.\\n \\n(Software\\n \\nEngineer)\\n \\nJune, 2012 \\n\\n \\nAugust\\n \\n2014\\n \\n\\n \\nI\\nmplementation and troubleshooting of client/server and enterprise applications using ASP.NET, C#.NET, \\nADO.NET and Win\\n \\nForms\\n \\n\\n \\nDay to day job involved developing, testing and maintaining application\\n \\nsoftware\\n \\n\\n \\nPossess good knowledge of software development life\\n \\ncycle\\n \\n \\nProjects and POCs:\\n \\nProject: Cannibalization\\n \\n\\n \\nWorked on predicting if new product launch will Cannibalize the existing similar\\n \\nproduct\\n \\n\\n \\nData preprocessing on \\nAzure\\n \\nmemsql\\n \\n\\n \\nCreated multiple models and selected \\nXGBOOST\\n \\n\\n \\nSelected Linear Regression for \\npredicting Cannibalization\\n \\nRate.\\n \\n\\n \\nFinding insights for the use case which helps to show it in our DIWO\\n \\nproduct.\\n \\n\\n \\nUsed \\nM\\nL\\n \\nflow\\n \\nContainerized Deployment on \\nAWS\\n \\nusing \\nAmazon SageMaker\\n \\nand ECS\\n \\n\\n \\nWork\\ned\\n \\non validating the\\n \\nresults.\\n \\nProject: Customer Revisit Propensit\\ny\\n \\n\\n \\nPredicted customer revisit propensity. Target variable was derived based on gap between transactions \\nof customer\\n \\n\\n \\nData preprocessing, data Transformation, feature engineering for entre\\n \\ndataset.\\n \\n\\n \\nPredictive imputation method(Decision tree) was used to ill t\\nhe missing values and based on\\n \\nfew\\n \\n'"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5ATSZNvNalq",
        "outputId": "f077f626-589b-4cbf-8d67-896abe671e1e"
      },
      "source": [
        "print(page_one.extractText())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kavitha Reddy\n",
            " \n",
            "Email ID: \n",
            "kavithareddybathini.522@gmail.com\n",
            ", \n",
            "Phone: 9000313641\n",
            " \n",
            " \n",
            "Summary:\n",
            " \n",
            "\n",
            " \n",
            "Process oriented Data Scientist with 2.8 years of experience and 4.8 years in\n",
            " \n",
            "SDLC.\n",
            " \n",
            "\n",
            " \n",
            "Experience in \n",
            "translating business requirements to Data science\n",
            " \n",
            "solutions\n",
            " \n",
            "\n",
            " \n",
            "Proficient in Statistical Analysis, Machine learning and Deep learning\n",
            " \n",
            "Algorithms\n",
            " \n",
            "\n",
            " \n",
            "Experienced in implementing CRISP\n",
            "-\n",
            "DM process for\n",
            " \n",
            "projects\n",
            " \n",
            "\n",
            " \n",
            "Have good exposure to advance programming in Python and\n",
            " \n",
            "R\n",
            " \n",
            "\n",
            " \n",
            "Good knowledge in Hadoop and its components like HDFS, Map Reduce, Apache Pig, Hive, Sqoop, HBase \n",
            "and\n",
            " \n",
            "Oozie.\n",
            " \n",
            "Experience:\n",
            " \n",
            "DatafactZ /Diwo\n",
            " \n",
            "(Data\n",
            " \n",
            "Scientist)\n",
            " \n",
            "April 2017 \n",
            "\n",
            " \n",
            "Dec\n",
            " \n",
            "2019\n",
            " \n",
            "\n",
            " \n",
            "Performed \n",
            "data analysis, statistical modeling, feature engineering, model tuni\n",
            "ng and selection \n",
            "on daily \n",
            "basis\n",
            " \n",
            "\n",
            " \n",
            "Used the concept of \n",
            "Stacking, Bagging, Boosting, Feature Importance and Selection, PCA \n",
            "etc. in real\n",
            "-\n",
            " \n",
            "world projects to enhance model\n",
            " \n",
            "performances\n",
            " \n",
            "\n",
            " \n",
            "Executed Projects for clients like \n",
            "L Brands , Flagstar and\n",
            " \n",
            "Aspire\n",
            " \n",
            "\n",
            " \n",
            "Implemented \n",
            "demand forecasting for predicting sales of a\n",
            " \n",
            "customer\n",
            " \n",
            "\n",
            " \n",
            "Involved with business stakeholders in developing HR analytics for customer\n",
            " \n",
            "retention\n",
            " \n",
            "\n",
            " \n",
            "Explored \n",
            "ML flow \n",
            "tool for hosting models in \n",
            "Azure\n",
            ", and calling using REST\n",
            " \n",
            "API\n",
            " \n",
            "\n",
            " \n",
            "Attended Weekly calls with the onsite \n",
            "team mainly interacting with \n",
            "Principal Business Architect\n",
            " \n",
            "and\n",
            " \n",
            "Senior Data Scientist \n",
            "Team\n",
            " \n",
            "\n",
            " \n",
            "Interacting with the business partners on regular basis for product\n",
            " \n",
            "enhancement\n",
            " \n",
            "\n",
            " \n",
            "Created ASK scenarios for ASK module in the DIWO product which shows the insights for t\n",
            "he\n",
            " \n",
            "business\n",
            " \n",
            "\n",
            " \n",
            "Engaging with clients to analyze opportunities for business growth and provide actionable\n",
            " \n",
            "insights\n",
            " \n",
            "\n",
            " \n",
            "Recognized as best employee of the month award in\n",
            " \n",
            "DataFactZ/Diwo\n",
            " \n",
            "Datapoint Info Solutions Pvt Ltd.\n",
            " \n",
            "(Software\n",
            " \n",
            "Engineer)\n",
            " \n",
            "June, 2012 \n",
            "\n",
            " \n",
            "August\n",
            " \n",
            "2014\n",
            " \n",
            "\n",
            " \n",
            "I\n",
            "mplementation and troubleshooting of client/server and enterprise applications using ASP.NET, C#.NET, \n",
            "ADO.NET and Win\n",
            " \n",
            "Forms\n",
            " \n",
            "\n",
            " \n",
            "Day to day job involved developing, testing and maintaining application\n",
            " \n",
            "software\n",
            " \n",
            "\n",
            " \n",
            "Possess good knowledge of software development life\n",
            " \n",
            "cycle\n",
            " \n",
            " \n",
            "Projects and POCs:\n",
            " \n",
            "Project: Cannibalization\n",
            " \n",
            "\n",
            " \n",
            "Worked on predicting if new product launch will Cannibalize the existing similar\n",
            " \n",
            "product\n",
            " \n",
            "\n",
            " \n",
            "Data preprocessing on \n",
            "Azure\n",
            " \n",
            "memsql\n",
            " \n",
            "\n",
            " \n",
            "Created multiple models and selected \n",
            "XGBOOST\n",
            " \n",
            "\n",
            " \n",
            "Selected Linear Regression for \n",
            "predicting Cannibalization\n",
            " \n",
            "Rate.\n",
            " \n",
            "\n",
            " \n",
            "Finding insights for the use case which helps to show it in our DIWO\n",
            " \n",
            "product.\n",
            " \n",
            "\n",
            " \n",
            "Used \n",
            "M\n",
            "L\n",
            " \n",
            "flow\n",
            " \n",
            "Containerized Deployment on \n",
            "AWS\n",
            " \n",
            "using \n",
            "Amazon SageMaker\n",
            " \n",
            "and ECS\n",
            " \n",
            "\n",
            " \n",
            "Work\n",
            "ed\n",
            " \n",
            "on validating the\n",
            " \n",
            "results.\n",
            " \n",
            "Project: Customer Revisit Propensit\n",
            "y\n",
            " \n",
            "\n",
            " \n",
            "Predicted customer revisit propensity. Target variable was derived based on gap between transactions \n",
            "of customer\n",
            " \n",
            "\n",
            " \n",
            "Data preprocessing, data Transformation, feature engineering for entre\n",
            " \n",
            "dataset.\n",
            " \n",
            "\n",
            " \n",
            "Predictive imputation method(Decision tree) was used to ill t\n",
            "he missing values and based on\n",
            " \n",
            "few\n",
            " \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etcIGCkQO3jT"
      },
      "source": [
        "#As the file is open we need to close the file\n",
        "myfile.close()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSXg9KUEPhrD"
      },
      "source": [
        "#Let's extract the content from current pdf page and paste it in a new pdf file. For that we need to open the file again \n",
        "\n",
        "p = open('Kavitha Reddy Resume.pdf',mode='rb')\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rX-f9sPeQhiH"
      },
      "source": [
        "pdf_reader = PyPDF2.PdfFileReader(p)       #Reading the file "
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANAHtzNbQ3_I"
      },
      "source": [
        "first_page = pdf_reader.getPage(0)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ET2mYjFJRDfj"
      },
      "source": [
        "#To write the content into new file we use PdffileWriter function\n",
        "pdf_writer = PyPDF2.PdfFileWriter()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxc0Oy3SRxDL"
      },
      "source": [
        "pdf_writer.addPage(first_page)   #Adding the page"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyjmC4ABSEme"
      },
      "source": [
        "pdf_output = open('Sample2.pdf',mode='wb')\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rx7m5hMqSLYt"
      },
      "source": [
        "pdf_writer.write(pdf_output)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQ5FWCe4SSwP"
      },
      "source": [
        "#CLose the files\n",
        "pdf_output.close()\n",
        "p.close()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAelYb55Si1E"
      },
      "source": [
        "#let's open the new file\n",
        "new_file = open('Sample2.pdf',mode='rb')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIQVyuc-TRtH"
      },
      "source": [
        "#To read the pdf file\n",
        "pdf_reader = PyPDF2.PdfFileReader(new_file)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k93Z39JVTZgE",
        "outputId": "20c13bfa-ee54-4f42-98ad-55c94845457d"
      },
      "source": [
        "pdf_reader.numPages"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2FrEQlPTgr6"
      },
      "source": [
        "new_page = pdf_reader.getPage(0)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0A00LkdTjKg",
        "outputId": "8d62fff8-31bd-4cbd-fbc7-7cb16f514681"
      },
      "source": [
        "print(new_page.extractText())"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kavitha Reddy\n",
            " \n",
            "Email ID: \n",
            "kavithareddybathini.522@gmail.com\n",
            ", \n",
            "Phone: 9000313641\n",
            " \n",
            " \n",
            "Summary:\n",
            " \n",
            "\n",
            " \n",
            "Process oriented Data Scientist with 2.8 years of experience and 4.8 years in\n",
            " \n",
            "SDLC.\n",
            " \n",
            "\n",
            " \n",
            "Experience in \n",
            "translating business requirements to Data science\n",
            " \n",
            "solutions\n",
            " \n",
            "\n",
            " \n",
            "Proficient in Statistical Analysis, Machine learning and Deep learning\n",
            " \n",
            "Algorithms\n",
            " \n",
            "\n",
            " \n",
            "Experienced in implementing CRISP\n",
            "-\n",
            "DM process for\n",
            " \n",
            "projects\n",
            " \n",
            "\n",
            " \n",
            "Have good exposure to advance programming in Python and\n",
            " \n",
            "R\n",
            " \n",
            "\n",
            " \n",
            "Good knowledge in Hadoop and its components like HDFS, Map Reduce, Apache Pig, Hive, Sqoop, HBase \n",
            "and\n",
            " \n",
            "Oozie.\n",
            " \n",
            "Experience:\n",
            " \n",
            "DatafactZ /Diwo\n",
            " \n",
            "(Data\n",
            " \n",
            "Scientist)\n",
            " \n",
            "April 2017 \n",
            "\n",
            " \n",
            "Dec\n",
            " \n",
            "2019\n",
            " \n",
            "\n",
            " \n",
            "Performed \n",
            "data analysis, statistical modeling, feature engineering, model tuni\n",
            "ng and selection \n",
            "on daily \n",
            "basis\n",
            " \n",
            "\n",
            " \n",
            "Used the concept of \n",
            "Stacking, Bagging, Boosting, Feature Importance and Selection, PCA \n",
            "etc. in real\n",
            "-\n",
            " \n",
            "world projects to enhance model\n",
            " \n",
            "performances\n",
            " \n",
            "\n",
            " \n",
            "Executed Projects for clients like \n",
            "L Brands , Flagstar and\n",
            " \n",
            "Aspire\n",
            " \n",
            "\n",
            " \n",
            "Implemented \n",
            "demand forecasting for predicting sales of a\n",
            " \n",
            "customer\n",
            " \n",
            "\n",
            " \n",
            "Involved with business stakeholders in developing HR analytics for customer\n",
            " \n",
            "retention\n",
            " \n",
            "\n",
            " \n",
            "Explored \n",
            "ML flow \n",
            "tool for hosting models in \n",
            "Azure\n",
            ", and calling using REST\n",
            " \n",
            "API\n",
            " \n",
            "\n",
            " \n",
            "Attended Weekly calls with the onsite \n",
            "team mainly interacting with \n",
            "Principal Business Architect\n",
            " \n",
            "and\n",
            " \n",
            "Senior Data Scientist \n",
            "Team\n",
            " \n",
            "\n",
            " \n",
            "Interacting with the business partners on regular basis for product\n",
            " \n",
            "enhancement\n",
            " \n",
            "\n",
            " \n",
            "Created ASK scenarios for ASK module in the DIWO product which shows the insights for t\n",
            "he\n",
            " \n",
            "business\n",
            " \n",
            "\n",
            " \n",
            "Engaging with clients to analyze opportunities for business growth and provide actionable\n",
            " \n",
            "insights\n",
            " \n",
            "\n",
            " \n",
            "Recognized as best employee of the month award in\n",
            " \n",
            "DataFactZ/Diwo\n",
            " \n",
            "Datapoint Info Solutions Pvt Ltd.\n",
            " \n",
            "(Software\n",
            " \n",
            "Engineer)\n",
            " \n",
            "June, 2012 \n",
            "\n",
            " \n",
            "August\n",
            " \n",
            "2014\n",
            " \n",
            "\n",
            " \n",
            "I\n",
            "mplementation and troubleshooting of client/server and enterprise applications using ASP.NET, C#.NET, \n",
            "ADO.NET and Win\n",
            " \n",
            "Forms\n",
            " \n",
            "\n",
            " \n",
            "Day to day job involved developing, testing and maintaining application\n",
            " \n",
            "software\n",
            " \n",
            "\n",
            " \n",
            "Possess good knowledge of software development life\n",
            " \n",
            "cycle\n",
            " \n",
            " \n",
            "Projects and POCs:\n",
            " \n",
            "Project: Cannibalization\n",
            " \n",
            "\n",
            " \n",
            "Worked on predicting if new product launch will Cannibalize the existing similar\n",
            " \n",
            "product\n",
            " \n",
            "\n",
            " \n",
            "Data preprocessing on \n",
            "Azure\n",
            " \n",
            "memsql\n",
            " \n",
            "\n",
            " \n",
            "Created multiple models and selected \n",
            "XGBOOST\n",
            " \n",
            "\n",
            " \n",
            "Selected Linear Regression for \n",
            "predicting Cannibalization\n",
            " \n",
            "Rate.\n",
            " \n",
            "\n",
            " \n",
            "Finding insights for the use case which helps to show it in our DIWO\n",
            " \n",
            "product.\n",
            " \n",
            "\n",
            " \n",
            "Used \n",
            "M\n",
            "L\n",
            " \n",
            "flow\n",
            " \n",
            "Containerized Deployment on \n",
            "AWS\n",
            " \n",
            "using \n",
            "Amazon SageMaker\n",
            " \n",
            "and ECS\n",
            " \n",
            "\n",
            " \n",
            "Work\n",
            "ed\n",
            " \n",
            "on validating the\n",
            " \n",
            "results.\n",
            " \n",
            "Project: Customer Revisit Propensit\n",
            "y\n",
            " \n",
            "\n",
            " \n",
            "Predicted customer revisit propensity. Target variable was derived based on gap between transactions \n",
            "of customer\n",
            " \n",
            "\n",
            " \n",
            "Data preprocessing, data Transformation, feature engineering for entre\n",
            " \n",
            "dataset.\n",
            " \n",
            "\n",
            " \n",
            "Predictive imputation method(Decision tree) was used to ill t\n",
            "he missing values and based on\n",
            " \n",
            "few\n",
            " \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_QKL8E9UH66"
      },
      "source": [
        "#To read entire file\n",
        "p = open('Sample2.pdf',mode='rb')\n",
        "pdf_text = []\n",
        "\n",
        "pdf_reader = PyPDF2.PdfFileReader(p)\n",
        "\n",
        "for q in range(pdf_reader.numPages):\n",
        "  page = pdf_reader.getPage(q)\n",
        "  pdf_text.append(page.extractText())\n",
        "\n",
        "p.close()"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRxSw7hwVyA0",
        "outputId": "61d1bd2f-1955-4938-f5b6-6b0468002075"
      },
      "source": [
        "len(pdf_text)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kogugugFV8x2",
        "outputId": "c610e008-9c2a-4d8f-8608-f851e5f5f544"
      },
      "source": [
        "for page in pdf_text:\n",
        "  print(page)\n",
        "  print('\\n')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kavitha Reddy\n",
            " \n",
            "Email ID: \n",
            "kavithareddybathini.522@gmail.com\n",
            ", \n",
            "Phone: 9000313641\n",
            " \n",
            " \n",
            "Summary:\n",
            " \n",
            "\n",
            " \n",
            "Process oriented Data Scientist with 2.8 years of experience and 4.8 years in\n",
            " \n",
            "SDLC.\n",
            " \n",
            "\n",
            " \n",
            "Experience in \n",
            "translating business requirements to Data science\n",
            " \n",
            "solutions\n",
            " \n",
            "\n",
            " \n",
            "Proficient in Statistical Analysis, Machine learning and Deep learning\n",
            " \n",
            "Algorithms\n",
            " \n",
            "\n",
            " \n",
            "Experienced in implementing CRISP\n",
            "-\n",
            "DM process for\n",
            " \n",
            "projects\n",
            " \n",
            "\n",
            " \n",
            "Have good exposure to advance programming in Python and\n",
            " \n",
            "R\n",
            " \n",
            "\n",
            " \n",
            "Good knowledge in Hadoop and its components like HDFS, Map Reduce, Apache Pig, Hive, Sqoop, HBase \n",
            "and\n",
            " \n",
            "Oozie.\n",
            " \n",
            "Experience:\n",
            " \n",
            "DatafactZ /Diwo\n",
            " \n",
            "(Data\n",
            " \n",
            "Scientist)\n",
            " \n",
            "April 2017 \n",
            "\n",
            " \n",
            "Dec\n",
            " \n",
            "2019\n",
            " \n",
            "\n",
            " \n",
            "Performed \n",
            "data analysis, statistical modeling, feature engineering, model tuni\n",
            "ng and selection \n",
            "on daily \n",
            "basis\n",
            " \n",
            "\n",
            " \n",
            "Used the concept of \n",
            "Stacking, Bagging, Boosting, Feature Importance and Selection, PCA \n",
            "etc. in real\n",
            "-\n",
            " \n",
            "world projects to enhance model\n",
            " \n",
            "performances\n",
            " \n",
            "\n",
            " \n",
            "Executed Projects for clients like \n",
            "L Brands , Flagstar and\n",
            " \n",
            "Aspire\n",
            " \n",
            "\n",
            " \n",
            "Implemented \n",
            "demand forecasting for predicting sales of a\n",
            " \n",
            "customer\n",
            " \n",
            "\n",
            " \n",
            "Involved with business stakeholders in developing HR analytics for customer\n",
            " \n",
            "retention\n",
            " \n",
            "\n",
            " \n",
            "Explored \n",
            "ML flow \n",
            "tool for hosting models in \n",
            "Azure\n",
            ", and calling using REST\n",
            " \n",
            "API\n",
            " \n",
            "\n",
            " \n",
            "Attended Weekly calls with the onsite \n",
            "team mainly interacting with \n",
            "Principal Business Architect\n",
            " \n",
            "and\n",
            " \n",
            "Senior Data Scientist \n",
            "Team\n",
            " \n",
            "\n",
            " \n",
            "Interacting with the business partners on regular basis for product\n",
            " \n",
            "enhancement\n",
            " \n",
            "\n",
            " \n",
            "Created ASK scenarios for ASK module in the DIWO product which shows the insights for t\n",
            "he\n",
            " \n",
            "business\n",
            " \n",
            "\n",
            " \n",
            "Engaging with clients to analyze opportunities for business growth and provide actionable\n",
            " \n",
            "insights\n",
            " \n",
            "\n",
            " \n",
            "Recognized as best employee of the month award in\n",
            " \n",
            "DataFactZ/Diwo\n",
            " \n",
            "Datapoint Info Solutions Pvt Ltd.\n",
            " \n",
            "(Software\n",
            " \n",
            "Engineer)\n",
            " \n",
            "June, 2012 \n",
            "\n",
            " \n",
            "August\n",
            " \n",
            "2014\n",
            " \n",
            "\n",
            " \n",
            "I\n",
            "mplementation and troubleshooting of client/server and enterprise applications using ASP.NET, C#.NET, \n",
            "ADO.NET and Win\n",
            " \n",
            "Forms\n",
            " \n",
            "\n",
            " \n",
            "Day to day job involved developing, testing and maintaining application\n",
            " \n",
            "software\n",
            " \n",
            "\n",
            " \n",
            "Possess good knowledge of software development life\n",
            " \n",
            "cycle\n",
            " \n",
            " \n",
            "Projects and POCs:\n",
            " \n",
            "Project: Cannibalization\n",
            " \n",
            "\n",
            " \n",
            "Worked on predicting if new product launch will Cannibalize the existing similar\n",
            " \n",
            "product\n",
            " \n",
            "\n",
            " \n",
            "Data preprocessing on \n",
            "Azure\n",
            " \n",
            "memsql\n",
            " \n",
            "\n",
            " \n",
            "Created multiple models and selected \n",
            "XGBOOST\n",
            " \n",
            "\n",
            " \n",
            "Selected Linear Regression for \n",
            "predicting Cannibalization\n",
            " \n",
            "Rate.\n",
            " \n",
            "\n",
            " \n",
            "Finding insights for the use case which helps to show it in our DIWO\n",
            " \n",
            "product.\n",
            " \n",
            "\n",
            " \n",
            "Used \n",
            "M\n",
            "L\n",
            " \n",
            "flow\n",
            " \n",
            "Containerized Deployment on \n",
            "AWS\n",
            " \n",
            "using \n",
            "Amazon SageMaker\n",
            " \n",
            "and ECS\n",
            " \n",
            "\n",
            " \n",
            "Work\n",
            "ed\n",
            " \n",
            "on validating the\n",
            " \n",
            "results.\n",
            " \n",
            "Project: Customer Revisit Propensit\n",
            "y\n",
            " \n",
            "\n",
            " \n",
            "Predicted customer revisit propensity. Target variable was derived based on gap between transactions \n",
            "of customer\n",
            " \n",
            "\n",
            " \n",
            "Data preprocessing, data Transformation, feature engineering for entre\n",
            " \n",
            "dataset.\n",
            " \n",
            "\n",
            " \n",
            "Predictive imputation method(Decision tree) was used to ill t\n",
            "he missing values and based on\n",
            " \n",
            "few\n",
            " \n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EJsHtjNlfY_"
      },
      "source": [
        "------------------"
      ]
    }
  ]
}